{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuHLIfXLUQu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "9fce3cf4-451f-4f2c-c503-9fcb3bf39e0c"
      },
      "source": [
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import ast\n",
        "import random\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read config\n",
        "config = {}\n",
        "with open(\"config.json\") as f:\n",
        "  config = json.load(f)[\"locations\"]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq9JS5a-Uj5e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0e95a5d-e757-4181-d760-4b956413f176"
      },
      "source": [
        "# Load citation dependency file and extract positive examples\n",
        "\n",
        "citation_dependency_file = config[\"zipped_patents\"]\n",
        "df = pd.read_csv(citation_dependency_file)\n",
        "positive_examples = []\n",
        "edge_list_df = df.apply(\n",
        "    lambda x: [positive_examples.append((x.patent, y)) for y in ast.literal_eval(x.citations)], \n",
        "    axis=1\n",
        ")\n",
        "all_1000_patents = []\n",
        "for item in positive_examples:\n",
        "  all_1000_patents.append(str(item[0]))\n",
        "  all_1000_patents.append(str(item[1]))\n",
        "all_1000_patents = set(all_1000_patents)\n",
        "len(all_1000_patents)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj1y-FCe_UXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5bed809f-4229-45a9-c23a-60443b67d55f"
      },
      "source": [
        "# Load embeddings file and check if all embeddings are valid\n",
        "\n",
        "embeddings_file = config[\"universal_embeddings\"]\n",
        "# embeddings_file = config[\"bert_embeddings\"]\n",
        "\n",
        "with open(embeddings_file) as f:\n",
        "  dat = json.load(f)\n",
        "  patents_embeddings_df = pd.DataFrame(dat)\n",
        "\n",
        "patents_with_embeddings = list(patents_embeddings_df.index.unique())\n",
        "patents_without_valid_embeddings = [x for x in patents_with_embeddings if (\n",
        "    not patents_embeddings_df.loc[x].embedding or \n",
        "    len(patents_embeddings_df.loc[x].embedding) == 500\n",
        "    )]\n",
        "\n",
        "if len(patents_without_valid_embeddings) > 0:\n",
        "  print(\"Some patents without embeddings found\")\n",
        "  [patents_embeddings_df.drop(x, inplace=True) for x in patents_without_valid_embeddings]\n",
        "\n",
        "patents_with_valid_embeddings = set([x.split(\".\")[0] for x in patents_embeddings_df.index])\n",
        "patents_with_valid_embeddings\n",
        "\n",
        "del patents_without_valid_embeddings\n",
        "del patents_with_embeddings\n",
        "len(patents_embeddings_df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some patents without embeddings found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umcoWzZ_rXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b0004cb-ddc6-4db8-d7be-6071abc2ada0"
      },
      "source": [
        "# Filter patents in all_1000_patents that have embeddings\n",
        "all_1000_patents_with_embeddings = set(all_1000_patents).intersection(patents_with_valid_embeddings)\n",
        "len(all_1000_patents_with_embeddings)  / len(all_1000_patents)\n",
        "\n",
        "# Find pairs that have embeddings\n",
        "positive_examples_with_text = ([\n",
        "  x\n",
        "  for x in positive_examples\n",
        "  if (\n",
        "      str(x[0]) in all_1000_patents_with_embeddings and \n",
        "      str(x[1]) in all_1000_patents_with_embeddings\n",
        "  )                               \n",
        "])\n",
        "\n",
        "# Contains 99.28% of positive_examples\n",
        "# len(positive_examples_with_text) / len(positive_examples)\n",
        "\n",
        "# Check if all embeddings have shape 512\n",
        "sum([len(x) for x in patents_embeddings_df.embedding]) == len(patents_embeddings_df) * 512"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4JKI8B3D9Qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract features for positive case\n",
        "\n",
        "feature1 = np.array([x[0] for x in positive_examples_with_text])\n",
        "feat_1_embedding = np.array([np.array(patents_embeddings_df.loc[f\"{x}.txt\"].embedding) for x in feature1])\n",
        "feat_1_embedding.shape\n",
        "\n",
        "feature2 = np.array([x[1] for x in positive_examples_with_text])\n",
        "feat_2_embedding = np.array([np.array(patents_embeddings_df.loc[f\"{x}.txt\"].embedding) for x in feature2])\n",
        "feat_2_embedding.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKe8y9f3FlNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3aabccd-6808-4373-ee21-85de9b843c05"
      },
      "source": [
        "## create negative examples:\n",
        "\n",
        "dependency_dict = {}\n",
        "def assign_to_dependency_dict(key, value):\n",
        "  dependency_dict[key] = value\n",
        "df.apply(\n",
        "    lambda x: assign_to_dependency_dict(x.patent, ast.literal_eval(x.citations)),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "all_false_edges = []\n",
        "count = 0\n",
        "for patent, dependents in dependency_dict.items():\n",
        "  patent = str(patent)\n",
        "  if patent not in all_1000_patents_with_embeddings:\n",
        "    # print(patent)\n",
        "    continue\n",
        "  # print(\"here\")\n",
        "  false_edges = []\n",
        "  num_edges = max((70 * len(dependents)) // 100, 50)\n",
        "  while len(false_edges) < num_edges:\n",
        "    candidate = random.choice(all_1000_patents)\n",
        "    if candidate != patent and candidate not in dependents and candidate in all_1000_patents_with_embeddings:\n",
        "      false_edges.append(candidate)\n",
        "      all_false_edges.append((str(patent), candidate))\n",
        "\n",
        "# \"3860003\" in all_1000_patents_with_embeddings\n",
        "len(all_false_edges)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceWdZKrPFuMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_feature1 = np.array([x[0] for x in all_false_edges])\n",
        "neg_feat_1_embedding = np.array([np.array(patents_embeddings_df.loc[f\"{x}.txt\"].embedding) for x in neg_feature1])\n",
        "print(neg_feat_1_embedding.shape)\n",
        "\n",
        "neg_feature2 = np.array([x[1] for x in all_false_edges])\n",
        "neg_feat_2_embedding = np.array([np.array(patents_embeddings_df.loc[f\"{x}.txt\"].embedding) for x in neg_feature1])\n",
        "print(neg_feat_2_embedding.shape)\n",
        "\n",
        "np.save(config[\"universal_feature_2\"], feat_2_embedding)\n",
        "np.save(config[\"universal_feature_1\"], feat_1_embedding)\n",
        "np.save(config[\"universal_feature_2_neg\"], neg_feat_2_embedding)\n",
        "np.save(config[\"universal_feature_1_neg\"], neg_feat_1_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiBXrZwrMEPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################  JUMP TO THIS CELL IF EMBEDDINGS ALREADY PRESENT #####################################\n",
        "\n",
        "\n",
        "# Uncomment and execute next 4 lines for Universal Sentence Embeddings\n",
        "\n",
        "# feat_1_embedding = np.load(config[\"universal_feature_1\"])\n",
        "# feat_2_embedding = np.load(config[\"universal_feature_2\"])\n",
        "# neg_feat_1_embedding = np.load(config[\"universal_feature_1_neg\"])\n",
        "# neg_feat_2_embedding = np.load(config[\"universal_feature_2_neg\"])\n",
        "\n",
        "# Uncomment following for BERT Embeddings\n",
        "\n",
        "# feat_1_embedding = np.load(config[\"bert_feature_1\"])\n",
        "# feat_2_embedding = np.load(config[\"bert_feature_2\"])\n",
        "# neg_feat_1_embedding = np.load(config[\"bert_feature_1_neg\"])\n",
        "# neg_feat_2_embedding = np.load(config[\"bert_feature_2_neg\"])\n",
        "\n",
        "###########################################################################################################\n",
        "\n",
        "\n",
        "positives = np.concatenate((feat_1_embedding, feat_2_embedding), axis=1).reshape((138856, 1024))\n",
        "negatives = np.concatenate((neg_feat_1_embedding, neg_feat_2_embedding), axis=1).reshape((96888, 1024))\n",
        "features = np.concatenate((positives, negatives), axis=0)\n",
        "labels = np.concatenate(\n",
        "  (\n",
        "      np.array([1] * positives.shape[0]),\n",
        "      np.array([0] * negatives.shape[0])\n",
        "  )  \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ9Goih9i0RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   features, labels, test_size=0.33, random_state=42)\n",
        "model = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFd2zq6nlK7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b9747ec1-ff4a-46dd-e8dc-fd2deb9461a7"
      },
      "source": [
        "print(\"test score: \", model.score(X_train, y_train))\n",
        "print(\"train score: \", model.score(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test score:  0.8486084027654671\n",
            "train score:  0.845454779166024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpIO1ppcq5_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as skm\n",
        "test_predictions = model.predict(X_test)\n",
        "print(skm.classification_report(y_test, test_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Classifier Data preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}